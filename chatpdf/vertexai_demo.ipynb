{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5abed32",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bestarch/Redis-Workshops/blob/main/11-LLM_GCP_Workshop/GCP_GenAI_demo_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HqRohfRRZgFWtj1zYJIyvR5n",
   "metadata": {
    "id": "HqRohfRRZgFWtj1zYJIyvR5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install required libraries\n",
    "!python3 -m pip -q install redis\n",
    "!pip install -U langchain-redis gradio\n",
    "!pip install -U langchain \n",
    "!pip install -U langchain-core\n",
    "!pip install -U langchain-google-vertexai\n",
    "%pip install -qU pypdf\n",
    "!pip install jupyterlab_widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sjUooyI9VlAu",
   "metadata": {
    "id": "sjUooyI9VlAu"
   },
   "outputs": [],
   "source": [
    "## Update the 'host' field with the correct Redis host URL\n",
    "host = 'redis-ds.c10.asia-south1-1.gce.redns.redis-cloud.com'\n",
    "port = 19205\n",
    "password = 'admin'\n",
    "requirePass = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4UnZUjIFVxWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UnZUjIFVxWA",
    "outputId": "b9c1b5f7-3ed7-41d0-c3bf-39486a9abb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "if requirePass:\n",
    "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
    "else:\n",
    "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
    "\n",
    "print(client.ping())\n",
    "# Clear Redis database (optional)\n",
    "\n",
    "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n",
    "INDEX_NAME = f\"idx_qna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnEl0UcxWV5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnEl0UcxWV5w",
    "outputId": "7724302c-2a67-4c99-a371-5cc43e6f53aa"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf -O report.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-B_EHwP7ouXf",
   "metadata": {
    "id": "-B_EHwP7ouXf"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "file = \"report.pdf\"\n",
    "\n",
    "# set up the file loader/extractor and text splitter to create chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500, chunk_overlap=50, add_start_index=True\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(file)\n",
    "documents = loader.load()\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "#chunked_docs = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "YrUStfXjniIa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrUStfXjniIa",
    "outputId": "67d1c52b-6b86-432a-b383-9ad556b95042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "chunked_docs = [doc.page_content for doc in chunks]\n",
    "print(len(chunks))\n",
    "print(len(chunked_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1c7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Already authenticated.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def check_and_authenticate():\n",
    "    adc_path = os.path.expanduser(\"~/.config/gcloud/application_default_credentials.json\")\n",
    "    if os.path.exists(adc_path):\n",
    "        print(\"âœ… Already authenticated.\")\n",
    "    else:\n",
    "        print(\"ðŸ”‘ Not authenticated. Starting login flow...\")\n",
    "        subprocess.run([\"gcloud\", \"auth\", \"application-default\", \"login\"])\n",
    "\n",
    "check_and_authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "#import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eWsh85l_sRvp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWsh85l_sRvp",
    "outputId": "5d5e57c1-9c2b-45da-d176-a25457997cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_google_vertexai import VertexAIEmbeddings\\nfrom google.colab import auth\\nfrom getpass import getpass\\nimport vertexai\\nimport google.auth\\nimport vertexai\\n\\n# input your GCP project ID and region for Vertex AI\\nPROJECT_ID = getpass(\"PROJECT_ID:\")\\nREGION = \\'us-central1\\' #input(\"REGION:\")\\n\\nauth.authenticate_user()\\n\\n#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\\nprint(\\'Authenticated\\')\\n\\n#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\\nvertexai.init(project=PROJECT_ID, location=REGION)\\n\\nprint(f\\'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}\\')\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Following code only works when running the notebook in Google Colab or GCP vertex AI Notebook\n",
    "'''\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from google.colab import auth\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "print('Authenticated')\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hKHXwtSGwNPr",
   "metadata": {
    "id": "hKHXwtSGwNPr"
   },
   "source": [
    "# Create text embeddings with Vertex AI embedding model\n",
    "\n",
    "Use the Vertex AI API for text embeddings, developed by Google.\n",
    "\n",
    "Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
    "\n",
    "\n",
    "*   Semantic search: Search text ranked by semantic similarity.\n",
    "*   Recommendation: Return items with text attributes similar to the given text.\n",
    "*   Classification: Return the class of items whose text attributes are similar to the given text.\n",
    "*   Clustering: Cluster items whose text attributes are similar to the given text.\n",
    "*   Outlier Detection: Return items where text attributes are least related to the given text.\n",
    "\n",
    "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The textembedding-gecko model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "A6H_vHkrSxco",
   "metadata": {
    "id": "A6H_vHkrSxco"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek.srivastava/apps/workspace/redis-ai/chatpdf/venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:15:21 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "# from langchain.vectorstores.redis import Redis\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.document_loaders import UnstructuredURLLoader\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "\n",
    "from langchain_redis import RedisVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "\n",
    "def get_vectordb():\n",
    "    \"\"\"Create the Redis vectordb.\"\"\"\n",
    "    # Load Redis with documents\n",
    "\n",
    "    vectordb = RedisVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=INDEX_NAME,\n",
    "    redis_url=REDIS_URL\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "redis = get_vectordb()\n",
    "\n",
    "#embedder = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kVJdyD1OVYE-",
   "metadata": {
    "id": "kVJdyD1OVYE-"
   },
   "source": [
    "# Include RAG\n",
    "\n",
    "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
    "\n",
    "Standard retrieval and chat completion\n",
    "Dense content representation to improve accuracy\n",
    "Query re-writing to improve accuracy\n",
    "Semantic caching to improve performance\n",
    "Conversational session history to improve personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "DYtdUxxFSxh9",
   "metadata": {
    "id": "DYtdUxxFSxh9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:08:47 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek.srivastava/apps/workspace/redis-ai/chatpdf/venv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#@title Invoke Google Vertex LLM using Langchain\n",
    "# This is where the Langchain brings all the components together in a form of a simple QnA chain\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_redis import RedisSemanticCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def cached_llm():\n",
    "    # Configure cache with all options\n",
    "    cache = RedisSemanticCache(\n",
    "        redis_url=REDIS_URL,\n",
    "        embeddings=embeddings,\n",
    "        distance_threshold=0.1,\n",
    "        ttl=7200,  # 2 hours\n",
    "        #namespace=\"llm_app_cache\"\n",
    "    )\n",
    "    \n",
    "    # Set global cache\n",
    "    set_llm_cache(cache)\n",
    "    \n",
    "    # Create LLM\n",
    "    llm = VertexAI(\n",
    "        model_name=\"gemini-2.5-pro\",\n",
    "        max_output_tokens=2048,\n",
    "        temperature=0.5,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "\n",
    "cached_llm = cached_llm()\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in chunks)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": redis.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | cached_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "XelSUbTkS7rj",
   "metadata": {
    "id": "XelSUbTkS7rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 44.7 ms, total: 208 ms\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "qa_chain.invoke('What may be some motivations for shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "B2f9CC3JI2BL",
   "metadata": {
    "id": "B2f9CC3JI2BL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 ms, sys: 14.5 ms, total: 63.3 ms\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "qa_chain.invoke('How do Indians like to pay for shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "LLHoWVshJJHK",
   "metadata": {
    "id": "LLHoWVshJJHK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 ms, sys: 13.1 ms, total: 57 ms\n",
      "Wall time: 1.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "qa_chain.invoke('What are some known challenges in shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5PVFYBW1NNKm",
   "metadata": {
    "id": "5PVFYBW1NNKm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('How home and kitchen segment is growing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bgfyRlzCNquj",
   "metadata": {
    "id": "bgfyRlzCNquj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('What are the effects of social media on online shopping?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "xClDk__XHFw-",
   "metadata": {
    "id": "xClDk__XHFw-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, motivations for online shopping differ by location. Urban dwellers are often motivated to shop online to avoid large crowds in malls and a lack of discounts in physical stores. For consumers in other parts of India, key drivers include the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products locally.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('What are some relevant items that are shopped online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "UmsYlwP9XZ2G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "UmsYlwP9XZ2G",
    "outputId": "627eb44a-ccef-4b86-e0e5-c4518c90baeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "12:17:16 httpx INFO   HTTP Request: GET http://127.0.0.1:7862/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "12:17:16 httpx INFO   HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n",
      "12:17:17 httpx INFO   HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "12:17:17 httpx INFO   HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://e2f1bf26ca46320657.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "12:17:23 httpx INFO   HTTP Request: HEAD https://e2f1bf26ca46320657.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e2f1bf26ca46320657.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def handle(query):\n",
    "    start_time = time.time()\n",
    "    response = qa.run(query)\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    return response, f\"Time: {processing_time:.2f} secs\"\n",
    "\n",
    "iface = gr.Interface(fn=handle, inputs=\"text\", outputs=[\n",
    "        gr.Textbox(label=\"Response\"),\n",
    "        gr.Textbox(label=\"Time\")\n",
    "    ], title=\"How India shops online?\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "nvmnrq_3YY6p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvmnrq_3YY6p",
    "outputId": "2eecf130-23be-4791-e8f9-0d0e28eb2e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75487654-4469-44fa-b7fc-9949b198417d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
