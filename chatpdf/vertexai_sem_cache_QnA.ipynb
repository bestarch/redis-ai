{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5abed32",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bestarch/Redis-Workshops/blob/main/11-LLM_GCP_Workshop/GCP_GenAI_demo_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HqRohfRRZgFWtj1zYJIyvR5n",
   "metadata": {
    "id": "HqRohfRRZgFWtj1zYJIyvR5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install required libraries\n",
    "!python3 -m pip -q install redis\n",
    "!pip install -U langchain-redis gradio\n",
    "!pip install -U langchain \n",
    "!pip install -U langchain-core\n",
    "!pip install -U langchain-google-vertexai\n",
    "!pip install jupyterlab_widgets\n",
    "%pip install -qU pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sjUooyI9VlAu",
   "metadata": {
    "id": "sjUooyI9VlAu"
   },
   "outputs": [],
   "source": [
    "## Update the 'host' field with the correct Redis host URL\n",
    "host = 'localhost'\n",
    "port = 6379\n",
    "password = 'admin'\n",
    "requirePass = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4UnZUjIFVxWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UnZUjIFVxWA",
    "outputId": "b9c1b5f7-3ed7-41d0-c3bf-39486a9abb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "if requirePass:\n",
    "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
    "else:\n",
    "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
    "\n",
    "print(client.ping())\n",
    "# Clear Redis database (optional)\n",
    "\n",
    "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n",
    "INDEX_NAME = f\"idx_qna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnEl0UcxWV5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnEl0UcxWV5w",
    "outputId": "7724302c-2a67-4c99-a371-5cc43e6f53aa"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf -O report.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-B_EHwP7ouXf",
   "metadata": {
    "id": "-B_EHwP7ouXf"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "file = \"report.pdf\"\n",
    "\n",
    "# set up the file loader/extractor and text splitter to create chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=50, add_start_index=True\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(file)\n",
    "documents = loader.load()\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "#chunked_docs = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "YrUStfXjniIa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrUStfXjniIa",
    "outputId": "67d1c52b-6b86-432a-b383-9ad556b95042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "chunked_docs = [doc.page_content for doc in chunks]\n",
    "print(len(chunks))\n",
    "print(len(chunked_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1c7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Already authenticated.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def check_and_authenticate():\n",
    "    adc_path = os.path.expanduser(\"~/.config/gcloud/application_default_credentials.json\")\n",
    "    if os.path.exists(adc_path):\n",
    "        print(\"âœ… Already authenticated.\")\n",
    "    else:\n",
    "        print(\"ðŸ”‘ Not authenticated. Starting login flow...\")\n",
    "        subprocess.run([\"gcloud\", \"auth\", \"application-default\", \"login\"])\n",
    "\n",
    "check_and_authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "#import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = 'central-beach-194106'#getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eWsh85l_sRvp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWsh85l_sRvp",
    "outputId": "5d5e57c1-9c2b-45da-d176-a25457997cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_google_vertexai import VertexAIEmbeddings\\nfrom google.colab import auth\\nfrom getpass import getpass\\nimport vertexai\\nimport google.auth\\nimport vertexai\\n\\n# input your GCP project ID and region for Vertex AI\\nPROJECT_ID = getpass(\"PROJECT_ID:\")\\nREGION = \\'us-central1\\' #input(\"REGION:\")\\n\\nauth.authenticate_user()\\n\\n#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\\nprint(\\'Authenticated\\')\\n\\n#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\\nvertexai.init(project=PROJECT_ID, location=REGION)\\n\\nprint(f\\'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}\\')\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Following code only works when running the notebook in Google Colab or GCP vertex AI Notebook\n",
    "'''\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from google.colab import auth\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "print('Authenticated')\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hKHXwtSGwNPr",
   "metadata": {
    "id": "hKHXwtSGwNPr"
   },
   "source": [
    "# Create text embeddings with Vertex AI embedding model\n",
    "\n",
    "Use the Vertex AI API for text embeddings, developed by Google.\n",
    "\n",
    "Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
    "\n",
    "\n",
    "*   Semantic search: Search text ranked by semantic similarity.\n",
    "*   Recommendation: Return items with text attributes similar to the given text.\n",
    "*   Classification: Return the class of items whose text attributes are similar to the given text.\n",
    "*   Clustering: Cluster items whose text attributes are similar to the given text.\n",
    "*   Outlier Detection: Return items where text attributes are least related to the given text.\n",
    "\n",
    "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The textembedding-gecko model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A6H_vHkrSxco",
   "metadata": {
    "id": "A6H_vHkrSxco"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain_redis import RedisVectorStore\n",
    "from langchain_core.documents import Document\n",
    "import vertexai\n",
    "\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "\n",
    "def get_vectordb():\n",
    "    \"\"\"Create the Redis vectordb.\"\"\"\n",
    "    # Load Redis with documents\n",
    "\n",
    "    vectordb = RedisVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=INDEX_NAME,\n",
    "    redis_url=REDIS_URL\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "redis = get_vectordb()\n",
    "\n",
    "#embedder = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kVJdyD1OVYE-",
   "metadata": {
    "id": "kVJdyD1OVYE-"
   },
   "source": [
    "# Include RAG\n",
    "\n",
    "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
    "\n",
    "Standard retrieval and chat completion\n",
    "Dense content representation to improve accuracy\n",
    "Query re-writing to improve accuracy\n",
    "Semantic caching to improve performance\n",
    "Conversational session history to improve personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad5e77-2ee8-4aea-8dd7-8b5bcdeeb72a",
   "metadata": {
    "id": "DYtdUxxFSxh9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek.srivastava/apps/workspace/redis-ai/chatpdf/venv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#@title Invoke Google Vertex LLM using Langchain\n",
    "# This is where the Langchain brings all the components together in a form of a simple QnA chain\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_redis import RedisSemanticCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.outputs import Generation\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "cache = RedisSemanticCache(\n",
    "    redis_url=REDIS_URL,\n",
    "    embeddings=embeddings,\n",
    "    distance_threshold=0.05,\n",
    "    ttl=900,  # 15 min\n",
    "    prefix=\"app_cache\"\n",
    ")\n",
    "\n",
    "# Create LLM\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-2.5-pro\",\n",
    "    max_output_tokens=2048,\n",
    "    temperature=0.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in chunks)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": redis.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2877d2-8349-47ca-a23b-4c3b2239157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "        \"What may be some motivations for shopping online?\",\n",
    "        \"What are some preferred methods of payment?\",\n",
    "        \"What are some known challenges in shopping online?\",\n",
    "        \"How home and kitchen segment is growing?\",\n",
    "        \"What are the effects of social media on shopping online?\",\n",
    "        \"What are some frequently bought items?\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "XelSUbTkS7rj",
   "metadata": {
    "id": "XelSUbTkS7rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What may be some motivations for shopping online?\n",
      "Cached response: Motivations for shopping online differ depending on the consumer's location. Urban dwellers often shop online to avoid large crowds in malls and due to a lack of discounts in physical stores. Consumers in other parts of India are motivated by the absence of physical stores for premium brands, product stockouts, and limited access to a wide range of products.\n",
      "\n",
      "Question: What are some preferred methods of payment?\n",
      "Cached response: Based on the provided context, payment preferences differ by location. Urban dwellers show a preference for UPI payments, followed by credit/debit cards. Conversely, consumers in the rest of India prefer cash on delivery (CoD) to minimize fraud risk, with Gen Z in these areas also favoring this method.\n",
      "\n",
      "Question: What are some known challenges in shopping online?\n",
      "Cached response: Known challenges in online shopping include concerns about payment fraud, the credibility of unfamiliar websites, and doubts about product quality matching online images. Shoppers are also deterred by fake reviews and logistical hurdles like inconsistent or slow deliveries. Additionally, urban consumers face challenges with delivery timings clashing with their fast-paced lifestyles.\n",
      "\n",
      "Question: How home and kitchen segment is growing?\n",
      "Cached response: The home and kitchen sector in the Indian market has experienced remarkable growth, expanding at a compound annual growth rate (CAGR) of 10%. This growth is driven by urbanization, a large young population, and the increasing aspirations of the burgeoning middle class. Furthermore, there is a growing preference among consumers for durable and versatile home spaces.\n",
      "\n",
      "Question: What are the effects of social media on shopping online?\n",
      "Cached response: Based on the provided text, social media has amplified awareness and aspirations, leading 62% of respondents to try products after seeing them on platforms like Facebook and Instagram. Influencers and visual content, such as unboxing videos on YouTube, also play a significant role in product discovery and influencing purchasing decisions. Overall, social media is the most preferred channel for encouraging trials of new products.\n",
      "\n",
      "Question: What are some frequently bought items?\n",
      "Cached response: According to the report, the most purchased categories vary by location. Urban residents focus more on grocery, electronics, and fashion and accessories. Consumers in the rest of India lead purchases in sports and fitness, home and kitchen, and health and wellness.\n",
      "\n",
      "CPU times: user 47.5 ms, sys: 29.1 ms, total: 76.6 ms\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = None\n",
    "for question in questions:\n",
    "   print(f\"Question: {question}\")\n",
    "   result = cache.lookup(question, \"vertexai/gemini-2.5-pro\")\n",
    "   if result:\n",
    "      print(f\"Cached response: {result[0].text}\\n\")\n",
    "   else:\n",
    "      result = qa_chain.invoke(question)\n",
    "      print(f\"LLM response: {result}\\n\")\n",
    "      # Update the cache with the new result\n",
    "      cache.update(question, \"vertexai/gemini-2.5-pro\", [Generation(text=result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UmsYlwP9XZ2G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "UmsYlwP9XZ2G",
    "outputId": "627eb44a-ccef-4b86-e0e5-c4518c90baeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "12:17:16 httpx INFO   HTTP Request: GET http://127.0.0.1:7862/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "12:17:16 httpx INFO   HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n",
      "12:17:17 httpx INFO   HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "12:17:17 httpx INFO   HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://e2f1bf26ca46320657.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "12:17:23 httpx INFO   HTTP Request: HEAD https://e2f1bf26ca46320657.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e2f1bf26ca46320657.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def handle(query):\n",
    "    start_time = time.time()\n",
    "    response = qa_chain.invoke(query)\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    return response, f\"Time: {processing_time:.2f} secs\"\n",
    "\n",
    "iface = gr.Interface(fn=handle, inputs=\"text\", outputs=[\n",
    "        gr.Textbox(label=\"Response\"),\n",
    "        gr.Textbox(label=\"Time\")\n",
    "    ], title=\"How India shops online?\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "nvmnrq_3YY6p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvmnrq_3YY6p",
    "outputId": "2eecf130-23be-4791-e8f9-0d0e28eb2e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75487654-4469-44fa-b7fc-9949b198417d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
