{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5abed32",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bestarch/Redis-Workshops/blob/main/11-LLM_GCP_Workshop/GCP_GenAI_demo_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HqRohfRRZgFWtj1zYJIyvR5n",
   "metadata": {
    "id": "HqRohfRRZgFWtj1zYJIyvR5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install required libraries\n",
    "!python3 -m pip -q install redis\n",
    "!pip install -U langchain-redis gradio\n",
    "!pip install -U langchain \n",
    "!pip install -U langchain-core\n",
    "!pip install -U langchain-google-vertexai\n",
    "!pip install jupyterlab_widgets\n",
    "%pip install -qU pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sjUooyI9VlAu",
   "metadata": {
    "id": "sjUooyI9VlAu"
   },
   "outputs": [],
   "source": [
    "## Update the 'host' field with the correct Redis host URL\n",
    "host = 'localhost'\n",
    "port = 6379\n",
    "password = 'admin'\n",
    "requirePass = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4UnZUjIFVxWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UnZUjIFVxWA",
    "outputId": "b9c1b5f7-3ed7-41d0-c3bf-39486a9abb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "if requirePass:\n",
    "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
    "else:\n",
    "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
    "\n",
    "print(client.ping())\n",
    "# Clear Redis database (optional)\n",
    "\n",
    "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n",
    "INDEX_NAME = f\"idx_qna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnEl0UcxWV5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnEl0UcxWV5w",
    "outputId": "7724302c-2a67-4c99-a371-5cc43e6f53aa"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf -O report.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1c7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Already authenticated.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def check_and_authenticate():\n",
    "    adc_path = os.path.expanduser(\"~/.config/gcloud/application_default_credentials.json\")\n",
    "    if os.path.exists(adc_path):\n",
    "        print(\"âœ… Already authenticated.\")\n",
    "    else:\n",
    "        print(\"ðŸ”‘ Not authenticated. Starting login flow...\")\n",
    "        subprocess.run([\"gcloud\", \"auth\", \"application-default\", \"login\"])\n",
    "\n",
    "check_and_authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "#import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = 'central-beach-194106'#getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eWsh85l_sRvp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWsh85l_sRvp",
    "outputId": "5d5e57c1-9c2b-45da-d176-a25457997cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_google_vertexai import VertexAIEmbeddings\\nfrom google.colab import auth\\nfrom getpass import getpass\\nimport vertexai\\nimport google.auth\\nimport vertexai\\n\\n# input your GCP project ID and region for Vertex AI\\nPROJECT_ID = getpass(\"PROJECT_ID:\")\\nREGION = \\'us-central1\\' #input(\"REGION:\")\\n\\nauth.authenticate_user()\\n\\n#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\\nprint(\\'Authenticated\\')\\n\\n#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\\nvertexai.init(project=PROJECT_ID, location=REGION)\\n\\nprint(f\\'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}\\')\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Following code only works when running the notebook in Google Colab or GCP vertex AI Notebook\n",
    "'''\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from google.colab import auth\n",
    "from getpass import getpass\n",
    "import vertexai\n",
    "import google.auth\n",
    "import vertexai\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
    "REGION = 'us-central1' #input(\"REGION:\")\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
    "print('Authenticated')\n",
    "\n",
    "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca3cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class PromptResponse(BaseModel):\n",
    "    prompt: str = Field(description=\"User input question about information in the document.\")\n",
    "    response: str = Field(description=\"Grounded answer from the LLM pertaining to the user's question.\")\n",
    "\n",
    "class FAQs(BaseModel):\n",
    "    pairs: List[PromptResponse] = Field(description=\"List of prompt response pairs extracted from the document\")\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "json_parser = JsonOutputParser(pydantic_object=FAQs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c92ba90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "# Create LLM\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-2.5-pro\",\n",
    "    max_output_tokens=2048,\n",
    "    temperature=0.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a document intelligence tool used to extract FAQs\n",
    "    from portions of a source PDF document. Put yourself in the shoes of a potential\n",
    "    reader of the provided material and anticipate what questions they might have.\n",
    "    Looking at the context below, your goal is to pull out some relevant question (prompt) \n",
    "    and answer (response) pairs, using only what's provided.\n",
    "\n",
    "    Other Rules:\n",
    "    - Create as many FAQs as possible, even rewording the same question and answer\n",
    "    a few times while remaining faithful to the truth and provided content.\n",
    "    - Ignore heavy marketing or salesly concepts and focus specifically on\n",
    "    factual data.\n",
    "    - Do not make up any information, only use what is provided in the context.\n",
    "    \n",
    "    {format_instructions}\n",
    "\n",
    "    Document Context:\\n{doc}\\n\"\"\",\n",
    "    input_variables=[\"doc\"],\n",
    "    partial_variables={\"format_instructions\": json_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "faq_generator_chain = prompt | llm | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ad5e77-2ee8-4aea-8dd7-8b5bcdeeb72a",
   "metadata": {
    "id": "DYtdUxxFSxh9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek.srivastava/apps/workspace/redis-ai/chatpdf/venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:16:23 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "#@title Invoke Google Vertex LLM using Langchain\n",
    "# This is where the Langchain brings all the components together in a form of a simple QnA chain\n",
    "from langchain_redis import RedisSemanticCache\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "model = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "cache = RedisSemanticCache(\n",
    "    redis_url=REDIS_URL,\n",
    "    embeddings=model,\n",
    "    distance_threshold=0.05,\n",
    "    ttl=900,  # 15 min\n",
    "    prefix=\"faq_cache\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb32524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file = \"report.pdf\"\n",
    "\n",
    "# set up the file loader/extractor and text splitter to create chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=50, add_start_index=True\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(file)\n",
    "documents = loader.load()\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunked_docs = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f880177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 96\n",
      "explore digital avenues.  \n",
      "4 https://www.businesstoday.in/latest/corporate/story/indians-spent-87-billion-hours-on-shopping-apps-in-2022 report-366927-2023-01-20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of chunks: {len(chunked_docs)}\")\n",
    "print(chunked_docs[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc3d8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of FAQs generated: 6\n",
      "Sample FAQ: {'prompt': 'What are the common reasons why people in India shop online?', 'response': 'Both urban dwellers and consumers from the rest of India make planned purchases online to access a wider range of price options and brands. Additionally, for both groups, browsing online shopping platforms during their free time can trigger a purchase.'}\n",
      "[{'prompt': 'What are the common reasons why people in India shop online?', 'response': 'Both urban dwellers and consumers from the rest of India make planned purchases online to access a wider range of price options and brands. Additionally, for both groups, browsing online shopping platforms during their free time can trigger a purchase.'}, {'prompt': \"What are the main motivators for consumers in the 'rest of India' to shop online?\", 'response': \"The primary reasons consumers in the 'rest of India' opt for online shopping are the absence of physical stores for premium brands, stockouts of certain products in local stores, and a lack of knowledgeable staff in offline retail environments.\"}, {'prompt': 'Why do urban dwellers in India prefer to shop online?', 'response': 'Urban dwellers are motivated to shop online due to the lack of discounts and special offers in physical stores and to avoid the large crowds often found in malls, particularly during weekends.'}, {'prompt': \"How does social media influence consumers' purchasing habits?\", 'response': 'Social media has significantly amplified awareness and aspirations, leading to 62% of survey respondents trying products after seeing them on platforms like Facebook and Instagram.'}, {'prompt': 'What percentage of people have tried a product after seeing it on social media?', 'response': 'According to the provided text, 62% of respondents have tried products after seeing them on Facebook and Instagram.'}, {'prompt': \"How does the influence of social media differ between urban dwellers and those in the 'rest of India'?\", 'response': \"For consumers in the 'rest of India', social media has become the most preferred channel for encouraging trials of new products.\"}]\n"
     ]
    }
   ],
   "source": [
    "faqs=[]  \n",
    "res = faq_generator_chain.invoke({\"doc\": chunked_docs[12]})\n",
    "if res:\n",
    "    faqs.extend(res['pairs'])\n",
    "    print(f\"Total number of FAQs generated: {len(res['pairs'])}\")\n",
    "    print(f\"Sample FAQ: {res['pairs'][0]}\")\n",
    "else:\n",
    "    print(\"No FAQs generated or unexpected response format.\")\n",
    "\n",
    "print(faqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b173198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing faq 1 of 6\n",
      "Processing faq 2 of 6\n",
      "Processing faq 3 of 6\n",
      "Processing faq 4 of 6\n",
      "Processing faq 5 of 6\n",
      "Processing faq 6 of 6\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.outputs import Generation\n",
    "from langchain_redis import RedisVectorStore\n",
    "from langchain_redis.cache import EmbeddingsVectorizer\n",
    "\n",
    "\n",
    "vectorizer = EmbeddingsVectorizer(embeddings=model)\n",
    "questions = [faq[\"prompt\"] for faq in faqs]\n",
    "for i, faq in enumerate(faqs):\n",
    "\tprint(f\"Processing faq {i+1} of {len(faqs)}\", flush=True)\n",
    "\tcache.update(faq[\"prompt\"], \"llm1\", [Generation(text=faq[\"response\"])])\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "XelSUbTkS7rj",
   "metadata": {
    "id": "XelSUbTkS7rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the common reasons why people in India shop online?\n",
      "Cached response: Both urban dwellers and consumers from the rest of India make planned purchases online to access a wider range of price options and brands. Additionally, for both groups, browsing online shopping platforms during their free time can trigger a purchase.\n",
      "\n",
      "Question: What are the main motivators for consumers in the 'rest of India' to shop online?\n",
      "Cached response: The primary reasons consumers in the 'rest of India' opt for online shopping are the absence of physical stores for premium brands, stockouts of certain products in local stores, and a lack of knowledgeable staff in offline retail environments.\n",
      "\n",
      "Question: Why do urban dwellers in India prefer to shop online?\n",
      "Cached response: Urban dwellers are motivated to shop online due to the lack of discounts and special offers in physical stores and to avoid the large crowds often found in malls, particularly during weekends.\n",
      "\n",
      "Question: How does social media influence consumers' purchasing habits?\n",
      "Cached response: Social media has significantly amplified awareness and aspirations, leading to 62% of survey respondents trying products after seeing them on platforms like Facebook and Instagram.\n",
      "\n",
      "Question: What percentage of people have tried a product after seeing it on social media?\n",
      "Cached response: According to the provided text, 62% of respondents have tried products after seeing them on Facebook and Instagram.\n",
      "\n",
      "Question: How does the influence of social media differ between urban dwellers and those in the 'rest of India'?\n",
      "Cached response: For consumers in the 'rest of India', social media has become the most preferred channel for encouraging trials of new products.\n",
      "\n",
      "CPU times: user 53.5 ms, sys: 33.4 ms, total: 86.9 ms\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = None\n",
    "for question in questions:\n",
    "   print(f\"Question: {question}\")\n",
    "   result = cache.lookup(question, \"llm1\")\n",
    "   if result:\n",
    "      print(f\"Cached response: {result[0].text}\\n\")\n",
    "   else:\n",
    "      print(f\"Cache miss for question: {question}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
